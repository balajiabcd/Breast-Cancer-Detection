{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-17T21:19:30.251420Z","iopub.execute_input":"2022-08-17T21:19:30.252127Z","iopub.status.idle":"2022-08-17T21:19:30.294414Z","shell.execute_reply.started":"2022-08-17T21:19:30.251973Z","shell.execute_reply":"2022-08-17T21:19:30.293474Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import random\nfrom sklearn.model_selection import train_test_split as tts\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:30.296632Z","iopub.execute_input":"2022-08-17T21:19:30.297423Z","iopub.status.idle":"2022-08-17T21:19:31.441533Z","shell.execute_reply.started":"2022-08-17T21:19:30.297387Z","shell.execute_reply":"2022-08-17T21:19:31.440066Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/breast-cancer-dataset/breast-cancer.csv\")\ndata.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.445280Z","iopub.execute_input":"2022-08-17T21:19:31.445768Z","iopub.status.idle":"2022-08-17T21:19:31.499576Z","shell.execute_reply.started":"2022-08-17T21:19:31.445723Z","shell.execute_reply":"2022-08-17T21:19:31.498237Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"#### Data has 32 columns. id, diagnosis, 10 variables of 3 types (Mean, se, worst) ","metadata":{}},{"cell_type":"markdown","source":"# Diagnosis are M = Malignent(Cancer) and B = Benign(No Cancer)","metadata":{}},{"cell_type":"code","source":"data.diagnosis.unique()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.501496Z","iopub.execute_input":"2022-08-17T21:19:31.502301Z","iopub.status.idle":"2022-08-17T21:19:31.516774Z","shell.execute_reply.started":"2022-08-17T21:19:31.502258Z","shell.execute_reply":"2022-08-17T21:19:31.515250Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"#### Observe no NaN in that column, which means we can use all the data with respect to Diagnosis column","metadata":{}},{"cell_type":"markdown","source":"# Assigning M to 1 and B to 0","metadata":{}},{"cell_type":"code","source":"data.diagnosis = (data.diagnosis == \"M\") * 1\ndata.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.520463Z","iopub.execute_input":"2022-08-17T21:19:31.520986Z","iopub.status.idle":"2022-08-17T21:19:31.553958Z","shell.execute_reply.started":"2022-08-17T21:19:31.520949Z","shell.execute_reply":"2022-08-17T21:19:31.552760Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.diagnosis.sum()","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.555570Z","iopub.execute_input":"2022-08-17T21:19:31.556085Z","iopub.status.idle":"2022-08-17T21:19:31.563471Z","shell.execute_reply.started":"2022-08-17T21:19:31.556048Z","shell.execute_reply":"2022-08-17T21:19:31.562600Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# General One Person Data ","metadata":{}},{"cell_type":"code","source":"print(len(data.iloc[2,:]),len(data))\ndata.iloc[2,:]","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.564797Z","iopub.execute_input":"2022-08-17T21:19:31.565288Z","iopub.status.idle":"2022-08-17T21:19:31.579488Z","shell.execute_reply.started":"2022-08-17T21:19:31.565258Z","shell.execute_reply":"2022-08-17T21:19:31.578653Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"#### Total 569 people went to Diagnosis","metadata":{}},{"cell_type":"code","source":"sns.histplot(x=data.diagnosis, color = \"lime\")","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.580985Z","iopub.execute_input":"2022-08-17T21:19:31.581477Z","iopub.status.idle":"2022-08-17T21:19:31.920239Z","shell.execute_reply.started":"2022-08-17T21:19:31.581446Z","shell.execute_reply":"2022-08-17T21:19:31.916730Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Heat map","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (30,30))\nsns.heatmap(data.corr(), cmap = sns.cubehelix_palette(8),annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:31.922113Z","iopub.execute_input":"2022-08-17T21:19:31.922521Z","iopub.status.idle":"2022-08-17T21:19:36.587459Z","shell.execute_reply.started":"2022-08-17T21:19:31.922484Z","shell.execute_reply":"2022-08-17T21:19:36.586390Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### We can see that radius_mean has stong corrilation with perinmeter_mean/worst, area_mean/worst, radius_worst. So we can remove these 5 variablis.","metadata":{}},{"cell_type":"markdown","source":"#### radius_se has strong corrilation with perimeter_se and area_se. So removing those 2","metadata":{}},{"cell_type":"markdown","source":"#### Concavity_mean has stron corrilation with concavepoints_mean/worst and conpactness_ mean, concavity_worst. So we remove these 4 variables.","metadata":{}},{"cell_type":"markdown","source":"#### Texture_worst and texture_mean are in corrilation. So we can remove one.","metadata":{}},{"cell_type":"code","source":"data = data.drop([\"perimeter_worst\", \"perimeter_mean\", \"area_mean\", \"area_worst\", \"radius_worst\", \n               \"compactness_mean\", \"concave points_mean\", \"concave points_worst\", \"concavity_worst\", \n               \"radius_se\", \"perimeter_se\",\"texture_worst\"], axis = 1)\n\nplt.figure(figsize = (20,20))\nsns.heatmap(data.corr(), cmap = sns.cubehelix_palette(8),annot = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:36.589112Z","iopub.execute_input":"2022-08-17T21:19:36.589930Z","iopub.status.idle":"2022-08-17T21:19:38.565436Z","shell.execute_reply.started":"2022-08-17T21:19:36.589887Z","shell.execute_reply":"2022-08-17T21:19:38.564375Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 6, ncols = 3, figsize = (20, 40))\na = 2\nfor i in range(6):\n    for j in range(3):\n        sns.histplot(data, x=data.columns[a], element = \"poly\", ax = ax[i,j], hue = \"diagnosis\" )\n        a = a+1","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:38.571164Z","iopub.execute_input":"2022-08-17T21:19:38.571998Z","iopub.status.idle":"2022-08-17T21:19:42.703394Z","shell.execute_reply.started":"2022-08-17T21:19:38.571954Z","shell.execute_reply":"2022-08-17T21:19:42.702204Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(nrows = 6, ncols = 3, figsize = (20, 40))\na = 2\nfor i in range(6):\n    for j in range(3):\n        sns.scatterplot(x='radius_mean', y=data.columns[a], data=data, hue='diagnosis', ax = ax[i,j])\n        a = a+1","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:42.705307Z","iopub.execute_input":"2022-08-17T21:19:42.705774Z","iopub.status.idle":"2022-08-17T21:19:47.088798Z","shell.execute_reply.started":"2022-08-17T21:19:42.705710Z","shell.execute_reply":"2022-08-17T21:19:47.087629Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for p in data.columns[2:]:\n    fig, ax = plt.subplots(nrows = 6, ncols = 3, figsize = (20,40))\n    a = 2\n    for i in range(6):\n        for j in range(3):\n            sns.scatterplot(x=data[p], y=data.columns[a], data=data, hue='diagnosis', ax = ax[i,j])\n            a = a+1","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:19:47.090040Z","iopub.execute_input":"2022-08-17T21:19:47.090974Z","iopub.status.idle":"2022-08-17T21:21:12.530330Z","shell.execute_reply.started":"2022-08-17T21:19:47.090941Z","shell.execute_reply":"2022-08-17T21:21:12.528973Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#### There are certainly some patterns to recognize Breast Cancer, based on the above 2 plots.","metadata":{}},{"cell_type":"markdown","source":"# Splitting Data into Train and Test data","metadata":{}},{"cell_type":"code","source":"Y = data.diagnosis\nX = data.drop(\"diagnosis\", axis = 1)\n\nX_train, X_test, Y_train, Y_test = tts(X, Y, random_state = 143, test_size = 0.4)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.531960Z","iopub.execute_input":"2022-08-17T21:21:12.532360Z","iopub.status.idle":"2022-08-17T21:21:12.543103Z","shell.execute_reply.started":"2022-08-17T21:21:12.532324Z","shell.execute_reply":"2022-08-17T21:21:12.541931Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Scaling ","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscalar = StandardScaler()\nscalar.fit_transform(X_train)\nscalar.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.545023Z","iopub.execute_input":"2022-08-17T21:21:12.545842Z","iopub.status.idle":"2022-08-17T21:21:12.570022Z","shell.execute_reply.started":"2022-08-17T21:21:12.545754Z","shell.execute_reply":"2022-08-17T21:21:12.569172Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# ConfusionMatrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error as mae","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.570996Z","iopub.execute_input":"2022-08-17T21:21:12.571342Z","iopub.status.idle":"2022-08-17T21:21:12.577772Z","shell.execute_reply.started":"2022-08-17T21:21:12.571299Z","shell.execute_reply":"2022-08-17T21:21:12.576145Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Linear Model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(X_train,Y_train)\npred = lr.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.578780Z","iopub.execute_input":"2022-08-17T21:21:12.579097Z","iopub.status.idle":"2022-08-17T21:21:12.673439Z","shell.execute_reply.started":"2022-08-17T21:21:12.579068Z","shell.execute_reply":"2022-08-17T21:21:12.672512Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.675217Z","iopub.execute_input":"2022-08-17T21:21:12.675533Z","iopub.status.idle":"2022-08-17T21:21:12.683659Z","shell.execute_reply.started":"2022-08-17T21:21:12.675505Z","shell.execute_reply":"2022-08-17T21:21:12.682908Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# SVM Model","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import LinearSVC\nsvc1 = LinearSVC(random_state =2)\nsvc1.fit(X_train,Y_train)\npred = svc1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.684987Z","iopub.execute_input":"2022-08-17T21:21:12.685280Z","iopub.status.idle":"2022-08-17T21:21:12.728620Z","shell.execute_reply.started":"2022-08-17T21:21:12.685253Z","shell.execute_reply":"2022-08-17T21:21:12.727760Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.730077Z","iopub.execute_input":"2022-08-17T21:21:12.730673Z","iopub.status.idle":"2022-08-17T21:21:12.738141Z","shell.execute_reply.started":"2022-08-17T21:21:12.730638Z","shell.execute_reply":"2022-08-17T21:21:12.737296Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# SVM model 2","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nsvc2 = SVC(kernel = \"rbf\", random_state = 2)\nsvc2.fit(X_train,Y_train)\npred = svc2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.739669Z","iopub.execute_input":"2022-08-17T21:21:12.740021Z","iopub.status.idle":"2022-08-17T21:21:12.762338Z","shell.execute_reply.started":"2022-08-17T21:21:12.739991Z","shell.execute_reply":"2022-08-17T21:21:12.761245Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.763682Z","iopub.execute_input":"2022-08-17T21:21:12.764048Z","iopub.status.idle":"2022-08-17T21:21:12.773748Z","shell.execute_reply.started":"2022-08-17T21:21:12.764016Z","shell.execute_reply":"2022-08-17T21:21:12.772497Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Naive Bayes Model","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train,Y_train)\npred = gnb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.775084Z","iopub.execute_input":"2022-08-17T21:21:12.775921Z","iopub.status.idle":"2022-08-17T21:21:12.789429Z","shell.execute_reply.started":"2022-08-17T21:21:12.775886Z","shell.execute_reply":"2022-08-17T21:21:12.788152Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.790914Z","iopub.execute_input":"2022-08-17T21:21:12.791249Z","iopub.status.idle":"2022-08-17T21:21:12.799824Z","shell.execute_reply.started":"2022-08-17T21:21:12.791219Z","shell.execute_reply":"2022-08-17T21:21:12.798664Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Model 1","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc1 = DecisionTreeClassifier(random_state = 2)\ndtc1.fit(X_train,Y_train)\npred = dtc1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.801634Z","iopub.execute_input":"2022-08-17T21:21:12.802419Z","iopub.status.idle":"2022-08-17T21:21:12.887735Z","shell.execute_reply.started":"2022-08-17T21:21:12.802373Z","shell.execute_reply":"2022-08-17T21:21:12.886688Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.889036Z","iopub.execute_input":"2022-08-17T21:21:12.889552Z","iopub.status.idle":"2022-08-17T21:21:12.896444Z","shell.execute_reply.started":"2022-08-17T21:21:12.889520Z","shell.execute_reply":"2022-08-17T21:21:12.895638Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree Model 2","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtc2 = DecisionTreeClassifier(random_state = 2,criterion = \"entropy\")\ndtc2.fit(X_train,Y_train)\npred = dtc2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.897651Z","iopub.execute_input":"2022-08-17T21:21:12.898063Z","iopub.status.idle":"2022-08-17T21:21:12.919457Z","shell.execute_reply.started":"2022-08-17T21:21:12.898022Z","shell.execute_reply":"2022-08-17T21:21:12.918080Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.921393Z","iopub.execute_input":"2022-08-17T21:21:12.922161Z","iopub.status.idle":"2022-08-17T21:21:12.929542Z","shell.execute_reply.started":"2022-08-17T21:21:12.922116Z","shell.execute_reply":"2022-08-17T21:21:12.928757Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Model 1","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc1 = RandomForestClassifier(random_state = 2, n_estimators = 10, criterion = \"gini\")\nrfc1.fit(X_train,Y_train)\npred = rfc1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:12.934376Z","iopub.execute_input":"2022-08-17T21:21:12.934963Z","iopub.status.idle":"2022-08-17T21:21:13.026239Z","shell.execute_reply.started":"2022-08-17T21:21:12.934929Z","shell.execute_reply":"2022-08-17T21:21:13.025101Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.027673Z","iopub.execute_input":"2022-08-17T21:21:13.028045Z","iopub.status.idle":"2022-08-17T21:21:13.036075Z","shell.execute_reply.started":"2022-08-17T21:21:13.028014Z","shell.execute_reply":"2022-08-17T21:21:13.035265Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Model 2","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc2 = RandomForestClassifier(random_state = 2, n_estimators = 10, criterion = \"entropy\")\nrfc2.fit(X_train,Y_train)\npred = rfc2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.037270Z","iopub.execute_input":"2022-08-17T21:21:13.038317Z","iopub.status.idle":"2022-08-17T21:21:13.073472Z","shell.execute_reply.started":"2022-08-17T21:21:13.038272Z","shell.execute_reply":"2022-08-17T21:21:13.072539Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.075125Z","iopub.execute_input":"2022-08-17T21:21:13.075494Z","iopub.status.idle":"2022-08-17T21:21:13.084649Z","shell.execute_reply.started":"2022-08-17T21:21:13.075459Z","shell.execute_reply":"2022-08-17T21:21:13.083374Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Model 3","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc3 = RandomForestClassifier(random_state = 2, n_estimators = 400, criterion = \"entropy\")\nrfc3.fit(X_train,Y_train)\npred = rfc3.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.085853Z","iopub.execute_input":"2022-08-17T21:21:13.086632Z","iopub.status.idle":"2022-08-17T21:21:13.907951Z","shell.execute_reply.started":"2022-08-17T21:21:13.086599Z","shell.execute_reply":"2022-08-17T21:21:13.906765Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.909405Z","iopub.execute_input":"2022-08-17T21:21:13.909867Z","iopub.status.idle":"2022-08-17T21:21:13.918676Z","shell.execute_reply.started":"2022-08-17T21:21:13.909833Z","shell.execute_reply":"2022-08-17T21:21:13.917478Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# KNN Model 1","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn1 = KNeighborsClassifier(p = 2, n_neighbors = 5)\nknn1.fit(X_train,Y_train)\npred = knn1.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.920307Z","iopub.execute_input":"2022-08-17T21:21:13.920936Z","iopub.status.idle":"2022-08-17T21:21:13.961543Z","shell.execute_reply.started":"2022-08-17T21:21:13.920895Z","shell.execute_reply":"2022-08-17T21:21:13.959906Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.964328Z","iopub.execute_input":"2022-08-17T21:21:13.965556Z","iopub.status.idle":"2022-08-17T21:21:13.979289Z","shell.execute_reply.started":"2022-08-17T21:21:13.965486Z","shell.execute_reply":"2022-08-17T21:21:13.977899Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# KNN Model 2","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn2 = KNeighborsClassifier(p = 2, n_neighbors = 15)\nknn2.fit(X_train,Y_train)\npred = knn2.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:13.981813Z","iopub.execute_input":"2022-08-17T21:21:13.983775Z","iopub.status.idle":"2022-08-17T21:21:14.021218Z","shell.execute_reply.started":"2022-08-17T21:21:13.983703Z","shell.execute_reply":"2022-08-17T21:21:14.019559Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"pred = [int(round(i,0)) for i in pred]\nmae(Y_test,pred) * 100","metadata":{"execution":{"iopub.status.busy":"2022-08-17T21:21:14.024039Z","iopub.execute_input":"2022-08-17T21:21:14.025259Z","iopub.status.idle":"2022-08-17T21:21:14.040889Z","shell.execute_reply.started":"2022-08-17T21:21:14.025192Z","shell.execute_reply":"2022-08-17T21:21:14.038814Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### The best prediction accuracy was obtainded by Random Forest model with n_estimators = 400(all data), criterion = \"entropy\". ","metadata":{}},{"cell_type":"markdown","source":"##### The accuracy best model on Test set of containg 40% of total data is 95.61%. ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}